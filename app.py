import streamlit as st
import os
import time
from deep_translator import GoogleTranslator
from audio_recorder_streamlit import audio_recorder
from streamlit_mic_recorder import mic_recorder,speech_to_text
import uuid
import io
from gtts import gTTS
import speech_recognition as sr
from openai import OpenAI
from dotenv import load_dotenv
from itertools import zip_longest
from streamlit_chat import message
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from operator import itemgetter
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda, RunnablePassthrough

def recognize_audio(audio_bytes, lang):
    query = ""  
    if audio_bytes:
        # st.audio(audio_bytes, format="audio/wav")
        r = sr.Recognizer()
        try:
            with io.BytesIO(audio_bytes) as wav_io:
                with sr.AudioFile(wav_io) as source:
                    audio_data = r.record(source)
                    query = r.recognize_google(audio_data, language= lang)  # Change the language code if needed
                    # st.warning(f"You: {query}\n")
        except sr.UnknownValueError:
            st.error("Google Speech Recognition could not understand audio.")
        except sr.RequestError as e:
            st.error(f"Could not request results from Google Speech Recognition service; {e}")
    
    return query

os.makedirs('Questions/English', exist_ok=True)
os.makedirs('Questions/Urdu', exist_ok=True)
os.makedirs('Questions/Spanish', exist_ok=True)
os.makedirs('Questions/Bengali', exist_ok=True)
os.makedirs('Questions/Arabic', exist_ok=True)

os.makedirs('Answers/English', exist_ok=True)
os.makedirs('Answers/Urdu', exist_ok=True)
os.makedirs('Answers/Spanish', exist_ok=True)
os.makedirs('Answers/Bengali', exist_ok=True)
os.makedirs('Answers/Arabic', exist_ok=True)


def speak(question, key, lang):
    if lang == 'en':
        folder_name = 'Questions/English'
    elif lang == 'es':
        folder_name = 'Questions/Spanish'
    elif lang == 'ur': 
        folder_name = 'Questions/Urdu'
    elif lang == 'bn': 
        folder_name = 'Questions/Bengali'
    elif lang == 'ar': 
        folder_name = 'Questions/Arabic'
    
    filename = f'{folder_name}/Q{key}.mp3'
    if not os.path.exists(filename):
        speech = gTTS(text=question, lang=lang, slow=False, tld="co.in")
        speech.save(filename)
    st.audio(filename)

def text_to_speech(answer, key, lang):
    speech = gTTS(text=answer, lang=lang, slow=False, tld="co.in")
    if lang == 'en':
        filename = f'Answers/English/A{key}.mp3'
        speech.save(filename)
    elif lang == 'ur':
        filename = f'Answers/Urdu/A{key}.mp3'
        speech.save(filename)
    elif lang == 'es':
        filename = f'Answers/Spanish/A{key}.mp3'
        speech.save(filename)
    elif lang == 'bn':
        filename = f'Answers/Bengali/A{key}.mp3'
        speech.save(filename)
    elif lang == 'ar':
        filename = f'Answers/Arabic/A{key}.mp3'
        speech.save(filename)
    st.audio(filename)

# load_dotenv()
# openai_api_key = os.getenv("OPENAI_API_KEY")
chat = ChatOpenAI(
    temperature=0.5,
    model_name="gpt-3.5-turbo",
    openai_api_key= st.secrets["OPENAI_API_KEY"],
    max_tokens=100,
)

questions = [
    ("What is your name?", 1, "╪в┘╛ ┌й╪з ┘Ж╪з┘Е ┌й┘К╪з █Б█Т?", "┬┐C├│mo te llamas?", "ржЖржкржирж╛рж░ ржирж╛ржо ржХрж┐?", "┘Е╪з ╪з╪│┘Е┘Г╪Я"),
    ("What is your age?", 2, "╪в┘╛ ┌й█М ╪╣┘Е╪▒ ┌й█М╪з █Б█Т╪Я", "┬┐Cu├бntos a├▒os tienes?", "ржЖржкржирж╛рж░ ржмржпрж╝рж╕ ржХржд?", "┘Е╪з ┘З┘И ╪╣┘Е╪▒┘Г╪Я"),
    ("What is your address?", 3, "╪в┘╛ ┌й╪з ┘╛╪к█Б ┌й█М╪з █Б█Т╪Я", "┬┐Cu├бl es su direcci├│n?", "ржЖржкржирж╛рж░ ржарж┐ржХрж╛ржирж╛ ржХрж┐?", "┘Е╪з ┘З┘И ╪╣┘Ж┘И╪з┘Ж┘Г╪Я"),
    ("Are you taking any Medications? If yes, then please tell name of the medication.", 4, "┌й█М╪з ╪в┘╛ ┌й┘И╪ж█М ╪п┘И╪з ┘Д█Т ╪▒█Б█Т █Б█М┌║╪Я╪з┌п╪▒ █Б╪з┌║. ┘╛┌╛╪▒ ╪п┘И╪з ┌й╪з ┘Ж╪з┘Е ╪и╪к╪з╪ж█М┌║ ", "┬┐Est├б tomando alg├║n medicamento? En caso afirmativo, indique el nombre del medicamento.", "ржЖржкржирж┐ ржХрж┐ ржХрзЛржирзЛ ржУрж╖рзБржз ржЦрж╛ржЪрзНржЫрзЗржи? ржпржжрж┐ рж╣рзНржпрж╛ржБ, рждрж╛рж╣рж▓рзЗ ржУрж╖рзБржзрзЗрж░ ржирж╛ржо ржмрж▓рзБржиред", "┘З┘Д ╪г┘Ж╪к ┘Е╪╣ ╪г┘К ╪г╪п┘И┘К╪й╪Я ╪е╪░╪з ┘Г╪з┘Ж╪к ╪з┘Д╪е╪м╪з╪и╪й ╪и┘Ж╪╣┘Е╪М ┘К╪▒╪м┘Й ╪░┘Г╪▒ ╪з╪│┘Е ╪з┘Д╪п┘И╪з╪б."),
    ("Can you name the medicines?", 5, "┌й█М╪з ╪в┘╛ ╪з╪п┘И█М╪з╪к ┌й█Т ┘Ж╪з┘Е ╪и╪к╪з ╪│┌й╪к█Т █Б█М┌║╪Я ", "┬┐Puedes nombrar los medicamentos?", "ржУрж╖рзБржзрзЗрж░ ржирж╛ржо ржмрж▓рждрзЗ ржкрж╛рж░ржмрзЗржи?", "┘З┘Д ┘К┘Е┘Г┘Ж┘Г ╪к╪│┘Е┘К╪й ╪з┘Д╪г╪п┘И┘К╪й╪Я"),
    ("What other medicine have you taken in the past?", 6, "╪в┘╛ ┘Ж█Т ┘Е╪з╪╢█М ┘Е█М┌║ ╪з┘И╪▒ ┌й┘И┘Ж ╪│█М ╪п┘И╪з ┘Д█М █Б█Т╪Я ", "┬┐Qu├й otro medicamento ha tomado en el pasado?", "ржЕрждрзАрждрзЗ ржЖржкржирж┐ ржЕржирзНржп ржХрзЛржи ржУрж╖рзБржз ржЦрзЗржпрж╝рзЗржЫрзЗржи?", "┘Е╪з ┘З┘К ╪з┘Д╪г╪п┘И┘К╪й ╪з┘Д╪г╪о╪▒┘Й ╪з┘Д╪к┘К ╪к┘Ж╪з┘И┘Д╪к┘З╪з ┘Б┘К ╪з┘Д┘Е╪з╪╢┘К╪Я"),
    ("What is your major complaint?", 7, "╪в┘╛ ┌й█М ╪│╪и ╪│█Т ╪и┌С█М ╪┤┌й╪з█М╪к ┌й█М╪з █Б█Т╪Я ", "┬┐Cu├бl es su principal queja?", "ржЖржкржирж╛рж░ ржкрзНрж░ржзрж╛ржи ржЕржнрж┐ржпрзЛржЧ ржХрж┐?", "┘Е╪з ┘З┘К ╪┤┘Г┘И╪з┘Г ╪з┘Д╪▒╪ж┘К╪│┘К╪й╪Я"),
    ("Have you previously suffered from this complaint?", 8, "┌й█М╪з ╪в┘╛ ┌й┘И ┘╛█Б┘Д█Т ╪и┌╛█М ╪з╪│ ╪┤┌й╪з█М╪к ┌й╪з ╪│╪з┘Е┘Ж╪з ┌й╪▒┘Ж╪з ┘╛┌С╪з █Б█Т╪Я", "┬┐Ha sufrido anteriormente esta dolencia?", "ржЖржкржирж┐ ржХрж┐ ржЖржЧрзЗ ржПржЗ ржЕржнрж┐ржпрзЛржЧ ржерзЗржХрзЗ ржнрзБржЧржЫрзЗржи?", "┘З┘Д ╪╣╪з┘Ж┘К╪к ┘Е┘Ж ┘В╪и┘Д ┘Е┘Ж ┘З╪░┘З ╪з┘Д╪┤┘Г┘И┘Й╪Я"),
    ("What previous therapists have you seen?", 9, "╪в┘╛ ┘Ж█Т ┘╛┌Ж┌╛┘Д█Т ┌й┘И┘Ж ╪│█Т ╪к┌╛╪▒╪з┘╛╪│┘╣ ┌й┘И ╪п█М┌й┌╛╪з █Б█Т╪Я", "┬┐A qu├й terapeuta has visto anteriormente?", "ржЖржкржирж┐ ржХрж┐ ржЖржЧрзЗрж░ ржерзЗрж░рж╛ржкрж┐рж╕рзНржЯ ржжрзЗржЦрзЗржЫрзЗржи?", "┘Е╪з ╪з┘Д┘Е╪╣╪з┘Д╪м┘К┘Ж ╪з┘Д╪│╪з╪и┘В┘К┘Ж ╪з┘Д╪░┘К┘Ж ╪▒╪г┘К╪к┘З┘Е╪Я"),
    ("Can you describe the treatment?", 10, "┌й█М╪з ╪в┘╛ ╪╣┘Д╪з╪м ┌й█М ┘И╪╢╪з╪н╪к ┌й╪▒ ╪│┌й╪к█Т █Б█М┌║╪Я", "┬┐Puede describir el tratamiento?", "ржЖржкржирж┐ ржЪрж┐ржХрж┐рждрзНрж╕рж╛ ржмрж░рзНржгржирж╛ ржХрж░рждрзЗ ржкрж╛рж░рзЗржи?", "┘З┘Д ┘К┘Е┘Г┘Ж┘Г ┘И╪╡┘Б ╪з┘Д╪╣┘Д╪з╪м╪Я"),
    ("What is your family history?", 11, "┌й█М╪з ╪в┘╛ ┘Е╪м┌╛█Т ╪з┘╛┘Ж█Т ╪о╪з┘Ж╪п╪з┘Ж ┌й█М ╪к╪з╪▒█М╪о ┌й█Т ╪и╪з╪▒█Т ┘Е█М┌║ ╪и╪к╪з ╪│┌й╪к█Т █Б█М┌║╪Я", "┬┐Cu├бl es su historia familiar?", "ржЖржкржирж╛рж░ ржкрж╛рж░рж┐ржмрж╛рж░рж┐ржХ ржЗрждрж┐рж╣рж╛рж╕ ржХрж┐?", "┘Е╪з ┘З┘И ╪к╪з╪▒┘К╪о ╪╣╪з╪ж┘Д╪к┘Г╪Я"),
    ("Are you adopted?", 12, "┌й█М╪з ╪в┘╛ ┌й┘И ┌п┘И╪п ┘Д█М╪з ┌п█М╪з ╪к┌╛╪з╪Я", "┬┐Eres adoptado?", "ржЖржкржирж┐ ржХрж┐ ржжрждрзНрждржХ?", "┘З┘Д ╪г┘Ж╪к ┘Е╪к╪и┘Ж┘Й╪Я"),
    ("If yes, at what age were you adopted?", 13, "╪з┌п╪▒ █Б╪з┌║╪М ╪к┘И ╪в┘╛ ┌й┘И ┌й╪│ ╪╣┘Е╪▒ ┘Е█М┌║ ┌п┘И╪п ┘Д█М╪з ┌п█М╪з ╪к┌╛╪з╪Я", "En caso afirmativo, ┬┐a qu├й edad fue adoptado?", "ржпржжрж┐ рж╣рзНржпрж╛ржБ, ржХрзЛржи ржмржпрж╝рж╕рзЗ ржЖржкржирж╛ржХрзЗ ржжрждрзНрждржХ ржирзЗржУржпрж╝рж╛ рж╣ржпрж╝рзЗржЫрж┐рж▓?", "╪е╪░╪з ┘Г╪з┘Ж╪к ╪з┘Д╪е╪м╪з╪и╪й ╪и┘Ж╪╣┘Е╪М ┘Б┘К ╪г┘К ╪╣┘Е╪▒ ╪к┘Е ╪к╪и┘Ж┘К┘Г╪Я"),
    ("How is your relationship with your mother?", 14, "┘Е╪з┌║ ┌й█Т ╪│╪з╪к┌╛ ╪в┘╛ ┌й╪з ╪▒╪┤╪к█Б ┌й█М╪│╪з █Б█Т╪Я", "┬┐C├│mo es tu relaci├│n con tu madre?", "ржЖржкржирж╛рж░ ржорж╛ржпрж╝рзЗрж░ рж╕рж╛ржерзЗ ржЖржкржирж╛рж░ рж╕ржорзНржкрж░рзНржХ ржХрзЗржоржи?", "┘Г┘К┘Б ┘З┘К ╪╣┘Д╪з┘В╪к┘Г ┘Е╪╣ ┘И╪з┘Д╪п╪к┘Г╪Я"),
    ("Where did you grow up?", 15, "╪в┘╛ ┌й█Б╪з┌║ ╪и┌С█Т █Б┘И╪ж█Т╪Я", "┬┐D├│nde creciste?", "ржЖржкржирж┐ ржХрзЛржерж╛ржпрж╝ ржмржбрж╝ рж╣ржпрж╝рзЗржЫрзЗржи?", "╪г┘К┘Ж ┘Ж╪┤╪г╪к╪Я"),
    ("Are you married?", 16, "┌й┘К╪з ╪в┘╛ ╪┤╪з╪п█М ╪┤╪п█Б █Б┘К┌║", "┬┐Est├бs casado?", "ржЖржкржирж┐ ржХрж┐ ржмрж┐ржмрж╛рж╣рж┐ржд?", "┘З┘Д ╪г┘Ж╪к ┘Е╪к╪▓┘И╪м╪Я"),
    ("If yes, specify the date of marriage?", 17, "╪з┌п╪▒ █Б╪з┌║╪М ╪к┘И ╪┤╪з╪п█М ┌й█М ╪к╪з╪▒█М╪о ╪и╪к╪з╪ж█М┌║╪Я", "En caso afirmativo, especifique la fecha del matrimonio.", "ржпржжрж┐ рж╣рзНржпрж╛ржБ, ржмрж┐ржпрж╝рзЗрж░ рждрж╛рж░рж┐ржЦ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░ржмрзЗржи?", "╪е╪░╪з ┘Г╪з┘Ж╪к ╪з┘Д╪е╪м╪з╪и╪й ╪и┘Ж╪╣┘Е╪М ╪н╪п╪п ╪к╪з╪▒┘К╪о ╪з┘Д╪▓┘И╪з╪м╪Я"),
    ("Do you have children?", 18, "┌й█М╪з ╪в┘╛ ┌й█Т ╪и┌Ж█Т █Б█М┌║╪Я", "┬┐Tienes hijos?", "ржЖржкржирж╛рж░ ржХрж┐ рж╕ржирзНрждрж╛ржи ржЖржЫрзЗ?", "┘З┘Д ┘Д╪п┘К┘Г ╪г╪╖┘Б╪з┘Д╪Я"),
    ("If yes, how is your relationship with your children?", 19, "┌й█М╪з ╪в┘╛ ┌й█Т ╪и┌Ж█Т █Б█М┌║╪Я", "En caso afirmativo, ┬┐c├│mo es su relaci├│n con sus hijos?", "ржпржжрж┐ рж╣рзНржпрж╛ржБ, ржЖржкржирж╛рж░ рж╕ржирзНрждрж╛ржиржжрзЗрж░ рж╕рж╛ржерзЗ ржЖржкржирж╛рж░ рж╕ржорзНржкрж░рзНржХ ржХрзЗржоржи?", "╪е╪░╪з ┘Ж╪╣┘Е ┘Г┘К┘Б ┘З┘К ╪╣┘Д╪з┘В╪к┘Г ┘Е╪╣ ╪г╪╖┘Б╪з┘Д┘Г╪Я"),
]

def generate_audio():
    for i, (en_question, key, ur_question, es_question, bn_question, ar_question) in enumerate(questions):
        if selected_language == 'en':
            speak(en_question, key, selected_language)
        elif selected_language == 'ur':
            speak(ur_question, key, selected_language)
        elif selected_language == 'es':
            speak(es_question, key, selected_language)
        elif selected_language == 'bn':
            speak(bn_question, key, selected_language)
        elif selected_language == 'ar':
            speak(ar_question, key, selected_language)

def intro():
    if selected_language == 'en':
        speak("Welcome to ICNA-Relief","0", 'en')
    elif selected_language == 'ur':
        speak("╪в╪ж█М ╪│█М ╪з█М┘Ж ╪з█Т ╪▒█М┘Д█М┘Б ┘Е█М┌║ ╪о┘И╪┤ ╪в┘Е╪п█М╪п. ╪┤┌й╪▒█М█Б", '0', 'ur')
    elif selected_language == 'es':
        speak("Bienvenidos a ICNA-Relief", '0', 'es')
    elif selected_language == 'bn':
        speak("ICNA-рж░рж┐рж▓рж┐ржлрзЗ рж╕рзНржмрж╛ржЧрждржо", '0', 'bn')
    elif selected_language == 'ar':
        speak("┘Е╪▒╪н╪и╪з ╪и┘Г┘Е ┘Б┘К ╪е╪║╪з╪л╪й ICNA", '0', 'ar')

st.set_page_config(
    page_title="OSTF App",
    page_icon="ЁЯзК",
    layout="wide",
)

st.header('Health Intake Questionnaire', divider='orange')
st.markdown('''Welcome To! I C N A - Releif Organization''')
selected_language = st.sidebar.selectbox("Select Language", ["en", "ur", "es", "bn", "ar"])
tab1, tab2 = st.tabs(["Q & A", "Translator"])

# Initialize session state variable
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

if 'generated' not in st.session_state:
    st.session_state['generated'] = []

if 'past' not in st.session_state:
    st.session_state['past'] = []  # Store past user inputs

# Define a function to generate response
def generate_response(user_query):
    # Build the list of messages
    zipped_messages = build_message_list(user_query)

    # Generate response using the chat model
    ai_response = chat(zipped_messages)
    response = ai_response.content
    return response

# Define a function to build a message list
def build_message_list(user_query):
    """
    Build a list of messages including system, human, and AI messages.
    """
    # Start zipped_messages with the SystemMessage
    zipped_messages = [SystemMessage(
        content= """You are a Health Care Expert for ICNA Relief, here to guide and assist people with their health questions and concerns. Please provide accurate and helpful information, and always maintain a polite and professional tone.
                    Your answer should be complete and precise.
                    If a user tell his/her name, age, address then just thank him and end the chat.
                    If a user tell his/her about personal life then just thank him and end the chat.
                    You have to answer briefly only health related questions.
                    You understand only these languages urdu, english, spanish, arabic and bengali.
                    If a user talk with different language which is not given then tell him I cannot understand your language."""
    )]

    # Zip together the past and generated messages
    for human_msg, ai_msg in zip_longest(st.session_state['past'], st.session_state['generated']):
        if human_msg is not None:
            zipped_messages.append(HumanMessage(
                content=human_msg))  # Add user messages
        if ai_msg is not None:
            zipped_messages.append(
                AIMessage(content=ai_msg))  # Add AI messages

    zipped_messages.append(HumanMessage(content=user_query))  # Add the latest user message

    return zipped_messages

user_input = ""

# Define a function to display the conversation history for text input in newest to oldest order
def display_text_conversation_history():
    for i in range(len(st.session_state['generated']) - 1, -1, -1):
        if i < len(st.session_state["past"]):
            message(st.session_state["past"][i], is_user=True, key=str(i) + '-text-user')
        message(st.session_state["generated"][i], key=str(i) + '-text')

# Define a function to display the conversation history for audio input in newest to oldest order
def display_audio_conversation_history():
    for i in range(len(st.session_state['generated']) - 1, -1, -1):
        if i < len(st.session_state["past"]):
            message(st.session_state["past"][i], is_user=True, key=str(i) + '-audio-user', avatar_style='lorelei')
        message(st.session_state["generated"][i], key=str(i) + '-audio', avatar_style='bottts')

if 'question_number' not in st.session_state:
    st.session_state.question_number = 1

# Create a sidebar
with st.sidebar:
    st.write("Introduction:")
    intro()
    # generate_audio()

# Display audio conversation history in the sidebar
with st.sidebar.expander("Conversation History"):
    display_audio_conversation_history()

with tab1:
    st.write(f"Question: {st.session_state.question_number}")
    speak(questions, st.session_state.question_number, selected_language)
    audio_bytes = audio_recorder(key=f"Q{st.session_state.question_number}",
                                 icon_size="2x")
    
    if selected_language == 'en':
        user_input = recognize_audio(audio_bytes, "en-EN")
    elif selected_language == 'ur':
        user_input = recognize_audio(audio_bytes, "ur-UR")
    elif selected_language == 'es':
        user_input = recognize_audio(audio_bytes, "es-ES")
    elif selected_language == 'bn':
        user_input = recognize_audio(audio_bytes, "bn-BD")
    elif selected_language == 'ar':
        user_input = recognize_audio(audio_bytes, "ar-SA")
    
    # Trigger a rerun to update the UI
    if st.button("Next Question тЦ╢я╕П", key=f"{selected_language}"):
        st.session_state.question_number += 1
        st.rerun()
    
    # st.divider()
    if user_input:
        # Append user query to past queries
        st.session_state.past.append(user_input)

        # Generate response
        output = generate_response(user_input)

        # Append AI response to generated responses
        st.session_state.generated.append(output)
        # User input
        st.markdown(f'<div class="chat-bubble user" id="bot-message">ЁЯд╡ЁЯП╗: {user_input}</div>', unsafe_allow_html=True)
        # Bot output
        st.markdown(f'<div class="chat-bubble bot" id="bot-message">ЁЯдЦ: {output}</div>', unsafe_allow_html=True)

        # Custom CSS
        st.markdown('''
            <style>
                .chat-bubble {
                    font-size: large;
                    color: white;
                    padding: 10px;
                    border-radius: 10px;
                    margin: 10px 0;
                    transition: background-color 0.3s;
                    cursor: pointer;
                    word-wrap: break-word;
                }

                .user {
                    background-color: #F36D1F;
                    overflow: hidden;
                    white-space: wrap;
                    width: 0;
                    animation: typing 1s steps(30, end) forwards;
                }

                .bot {
                    background-color: black;
                    overflow: hidden;
                    white-space: wrap;
                    width: 0;
                    animation: typing 1s steps(30, end) forwards;
                }

                .chat-bubble:hover {
                    background-color: #555;
                }

                @keyframes typing {
                    from {
                        width: 0;
                    }
                    to {
                        width: 100%;
                    }
                }
            </style>
        ''', unsafe_allow_html=True)

        # Custom JavaScript
        st.markdown('''
            <script>
                setTimeout(function() {
                    document.getElementById('bot-message').innerHTML += ' {message}';
                }, 2000);
            </script>
        ''', unsafe_allow_html=True)
        text_to_speech(output, st.session_state.question_number, selected_language)

    else:
        if selected_language == 'en':
            if 'en' != selected_language:
                st.warning("Please select the language first.")
        elif selected_language == 'ur':
            if 'ur' != selected_language:
                st.warning("╪и╪▒╪з█Б ┘Е█Б╪▒╪и╪з┘Ж█М ╪п┘И╪│╪▒█Т ╪│┘И╪з┘Д ┌й█М ╪╖╪▒┘Б ╪м╪з╪ж█М┌║█Ф")
        elif selected_language == 'es':
            if 'es' != selected_language:
                st.warning("Por favor, seleccione el idioma primero.")
        elif selected_language == 'bn':
            if 'bn' != selected_language:
                st.warning("ржкрзНрж░ржержорзЗ ржнрж╛рж╖рж╛ ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзБржи.")
        elif selected_language == 'ar':
            if 'ar' != selected_language:
                st.warning("╪з┘Д╪▒╪м╪з╪б ╪к╪н╪п┘К╪п ╪з┘Д┘Д╪║╪й ╪г┘И┘Д╪з.")
            
            
#------------------------------------------------------------------------------------
def display_languages(languages):
    st.subheader("Language Names")

    # Extract language names from the list of tuples
    language_names = [lang[0] for lang in languages]
    st.write(language_names)
    
dic = [
    ('arabic', 'ar', 'ar-SA'),
    ('bengali', 'bn', 'bn-BD'),
    ('english', 'en', 'en-EN'),
    ('french', 'fr', 'fr-FR'),
    ('german', 'de', 'de-DE'),
    ('gujarati', 'gu', 'gu-IN'),
    ('hindi', 'hi', 'hi-IN'),
    ('italian', 'it', 'it-IT'),
    ('japanese', 'ja', 'ja-JP'),
    ('korean', 'ko', 'ko-KR'),
    ('malayalam', 'ml', 'ml-IN'),
    ('marathi', 'mr', 'mr-IN'),
    ('nepali', 'ne', 'ne-NP'),
    ('russian', 'ru', 'ru-RU'),
    ('spanish', 'es', 'es-ES'),
    ('tamil', 'ta', 'ta-IN'),
    ('urdu', 'ur', 'ur-UR')
]


def bolo(question, lang):
    speech = gTTS(text=question, lang=lang, slow=False, tld="co.in")
    key = str(uuid.uuid4())
    filename = f'Languages/{lang+"_"+key}.mp3'
    speech.save(filename)
    with st.spinner('Wait for it...'):
        time.sleep(2)
    return st.audio(f'Languages/{lang+"_"+key}.mp3')

# Make a folder
os.makedirs('Languages', exist_ok=True)

with tab2:
    display_languages(dic)

    # Display selected language code
    col1, col2 = st.columns(2)
    
    with col1:
        selected_language = st.selectbox("Select source language", [lang[0] for lang in dic], key="source")
        selected_language_code = [lang[1] for lang in dic if lang[0] == selected_language][0]
        selected_language_code_with_country = [lang[2] for lang in dic if lang[0] == selected_language][0]
        
        audio_bytes = audio_recorder(key= "Translate",
                                     icon_size="2x")
        # st.write(selected_language_code)
        # st.write(selected_language_code_with_country)
        # st.caption("Complete voice message in 10 secs")
        if audio_bytes:
            st.audio(audio_bytes, format="audio/mp3")
            # st.caption("Source voice")
            r = sr.Recognizer()
            try:
                with io.BytesIO(audio_bytes) as wav_io:
                    with sr.AudioFile(wav_io) as source:
                        audio_data = r.record(source)
                        query = r.recognize_google(audio_data, language = selected_language_code_with_country)  # Change the language code if needed
                        st.success(f"You: {query}\n")
            except sr.UnknownValueError:
                st.error("Google Speech Recognition could not understand audio.")
            except sr.RequestError as e:
                st.error(f"Could not request results from Google Speech Recognition service; {e}")

    with col2:
        selected_language = st.selectbox("Select source language", [lang[0] for lang in dic], key="convert")
        selected_language_code = [lang[1] for lang in dic if lang[0] == selected_language][0]
        selected_language_code_with_country = [lang[2] for lang in dic if lang[0] == selected_language][0]
        
        if 'query' in locals():
            translated = GoogleTranslator(source='auto', target=f'{selected_language}').translate(query)
            st.warning("Translating...")

            # Generate the audio
            audio = bolo(translated, selected_language_code)
            # st.caption("Target Voice")
            st.success(f"Translate: {translated}")
    